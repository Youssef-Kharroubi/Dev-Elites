{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d955429d",
   "metadata": {},
   "source": [
    "# Phase 1: Business Understanding\n",
    "\n",
    "## Project context\n",
    "\n",
    "The health insurance sector in Tunisia has seen significant growth in recent years, driven by the increasing demand for better healthcare coverage. While these companies play a crucial role in society, handling large volumes of paperwork remains a major challenge.\n",
    "\n",
    "Health insurance companies process vast amounts of medical documents daily. Manual categorization is **time-consuming, error-prone, and inefficient**. The objective of this project is to **automate document classification**, minimizing human intervention while improving speed and accuracy.\n",
    "\n",
    "### Objective\n",
    "We aim to develop an **automated document classification model** using **convolutional neural networks (CNNs)**. The model will distinguish between two primary categories of medical documents:\n",
    "\n",
    "1. **Medical Care Forms** – Documents related to health insurance claims.\n",
    "2. **Prescriptions** – Documents containing doctor-issued prescriptions for medications.\n",
    "\n",
    "To ensure optimal performance, we will also **experiment with a pre-trained model** (VGG16) and compare its results against our custom CNN model. The most effective model will be selected to enhance the **document management workflow** in health insurance companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29fb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c053c1d",
   "metadata": {},
   "source": [
    "# **Phase 2: Data Acquisition and Understanding**\n",
    "\n",
    "## **Dataset Overview**\n",
    "To build our medical document classification model, we collected three types of medical documents:\n",
    "\n",
    "- **Medical Care Forms**: 1,600 images  \n",
    "- **Prescriptions**: 580 images  \n",
    "\n",
    "These documents were sourced from a **health insurance company** and stored in a folder named `dataset_classification`. Each category contains scanned images of medical documents with varying resolutions, formats, and quality.\n",
    "\n",
    "## **Data Preprocessing**\n",
    "To enhance the quality of the images and ensure consistency, we applied several preprocessing steps:\n",
    "\n",
    "### **1. Grayscale Conversion**\n",
    "Since color information is not critical for document classification, we converted all images to grayscale to reduce computational complexity and focus on text-based features.\n",
    "\n",
    "### **2. Image Sharpening**\n",
    "To enhance text clarity and improve feature detection, we applied sharpening using `ImageEnhance.Sharpness`. This step increases the contrast between text and background, making classification easier.\n",
    "\n",
    "### **3. Resizing**\n",
    "All images were resized to a uniform **512x512 pixels** using the **LANCZOS** resampling method to standardize input dimensions for our deep learning model.\n",
    "\n",
    "### **4. Further Enhancement**\n",
    "After resizing, an additional sharpening step was applied to further improve document readability.\n",
    "\n",
    "### **5. Dataset Splitting**\n",
    "After preprocessing, the dataset was split into **training**, **validation** and **test** sets:\n",
    "\n",
    "- **Training Set**: 80% of the images  \n",
    "- **Validation Set**: 20% of the images  \n",
    "\n",
    "Each class folder was split while maintaining balance, ensuring that the model learns meaningful representations without bias toward any category.\n",
    "Additionally, we randomly selected 53 images and set them aside as a test set. These images will not be used during training or validation but will serve as a final evaluation to measure how well the model generalizes to unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"dataset_classification\\Others\"\n",
    "output_dir = r\"preprocessed_dataset\\Processed_Others\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "TARGET_SIZE = (512, 512) \n",
    "\n",
    "def preprocess_image(image_path, output_path):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    gray_image = image.convert(\"L\")\n",
    "\n",
    "    enhancer = ImageEnhance.Sharpness(gray_image)\n",
    "    sharp_image = enhancer.enhance(2.0) \n",
    "\n",
    "    resized_image = sharp_image.resize(TARGET_SIZE, Image.LANCZOS)\n",
    "\n",
    "    enhancer = ImageEnhance.Sharpness(resized_image)\n",
    "    final_image = enhancer.enhance(1.5) \n",
    "\n",
    "    final_image.save(output_path, dpi=(300, 300), quality=95) \n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        preprocess_image(input_path, output_path)\n",
    "\n",
    "print(\"Image preprocessing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_dir = r\"preprocessed_dataset\"\n",
    "train_dir = r\"train_dataset\"\n",
    "val_dir = r\"validation_dataset\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "split_ratio = 0.2\n",
    "\n",
    "for class_folder in os.listdir(input_dir):\n",
    "    class_path = os.path.join(input_dir, class_folder)\n",
    "    train_class_path = os.path.join(train_dir, class_folder)\n",
    "    val_class_path = os.path.join(val_dir, class_folder)\n",
    "    \n",
    "    if os.path.isdir(class_path):\n",
    "        os.makedirs(train_class_path, exist_ok=True)\n",
    "        os.makedirs(val_class_path, exist_ok=True)\n",
    "        images = [img for img in os.listdir(class_path) if img.endswith(('.jpg', '.png'))]\n",
    "        val_size = int(len(images) * split_ratio)\n",
    "        val_images = random.sample(images, val_size)\n",
    "        \n",
    "        for img in val_images:\n",
    "            shutil.move(os.path.join(class_path, img), os.path.join(val_class_path, img))\n",
    "        \n",
    "        for img in os.listdir(class_path):\n",
    "            shutil.move(os.path.join(class_path, img), os.path.join(train_class_path, img))\n",
    "\n",
    "print(\"Dataset split into Train & Validation!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
