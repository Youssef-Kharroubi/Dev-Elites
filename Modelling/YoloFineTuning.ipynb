{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225fc1af-073a-4dc0-941e-1436dab25b9a",
   "metadata": {},
   "source": [
    "## fine tuning YOLOv8 model to better detect bounding boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53578d3b-1062-4773-98b5-8233699ca496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from shutil import copyfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f7c076-005a-4820-9e13-51f3459166ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "\n",
    "# def crop_right_page(source_folder, output_folder):\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     supported_ext = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "#     for filename in os.listdir(source_folder):\n",
    "#         if filename.lower().endswith(supported_ext):\n",
    "#             input_path = os.path.join(source_folder, filename)\n",
    "#             image = cv2.imread(input_path)\n",
    "\n",
    "#             if image is None:\n",
    "#                 print(f\"Could not read image: {input_path}\")\n",
    "#                 continue\n",
    "\n",
    "#             height, width = image.shape[:2]\n",
    "#             mid_x = width // 2\n",
    "\n",
    "#             # Crop the right half\n",
    "#             cropped_image = image[0:height, mid_x:width]\n",
    "\n",
    "#             # Save the cropped image\n",
    "#             base, ext = os.path.splitext(filename)\n",
    "#             new_filename = f\"{base}_right{ext}\"\n",
    "#             output_path = os.path.join(output_folder, new_filename)\n",
    "\n",
    "#             cv2.imwrite(output_path, cropped_image)\n",
    "#             print(f\"Cropped right page and saved: {output_path}\")\n",
    "\n",
    "# # Usage\n",
    "# crop_right_page(\"../data/new_generated_forms/clust0\", \"data_to_annotate/Bh_temp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af06b88-d5e9-40bb-a1ad-faddc50f0c5b",
   "metadata": {},
   "source": [
    "### Classifying Medical_form front and back page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5234ec3-cb75-4dab-ba01-728debca10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from shutil import copyfile\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # === CONFIGURATION ===\n",
    "# source_folder = \"../data/generated_forms\"\n",
    "# output_folder_0 = \"../data/new_generated_forms/clust0\"\n",
    "# output_folder_1 = \"../data/new_generated_forms/clust1\"\n",
    "# image_size = (128, 128)  # Force same size for consistency\n",
    "\n",
    "# # === PREPARE FOLDERS ===\n",
    "# os.makedirs(output_folder_0, exist_ok=True)\n",
    "# os.makedirs(output_folder_1, exist_ok=True)\n",
    "\n",
    "# # === LOAD AND FLATTEN IMAGES ===\n",
    "# image_paths = []\n",
    "# features = []\n",
    "\n",
    "# for filename in os.listdir(source_folder):\n",
    "#     if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "#         path = os.path.join(source_folder, filename)\n",
    "#         img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "#         if img is None:\n",
    "#             print(f\"Skipping unreadable image: {filename}\")\n",
    "#             continue\n",
    "#         img = cv2.resize(img, image_size)  # Ensures fixed shape\n",
    "#         img_flat = img.flatten()\n",
    "#         features.append(img_flat)\n",
    "#         image_paths.append(path)\n",
    "#         print(f\"Loaded: {filename}\")\n",
    "\n",
    "# print(\"------------------------------------------------end loading---------------------------------------------\")\n",
    "# features = np.array(features)\n",
    "\n",
    "# # === APPLY K-MEANS ===\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "# labels = kmeans.fit_predict(features)\n",
    "\n",
    "# # === SAVE IMAGES INTO CLUSTERS ===\n",
    "# for path, label in zip(image_paths, labels):\n",
    "#     filename = os.path.basename(path)\n",
    "#     dest_folder = output_folder_0 if label == 0 else output_folder_1\n",
    "#     copyfile(path, os.path.join(dest_folder, filename))\n",
    "#     print(f\"Image saved to cluster {label}: {filename}\")\n",
    "\n",
    "# print(\"✅ Images clustered and saved into folders!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d37674-839d-4bf2-95c2-32f18d03f141",
   "metadata": {},
   "source": [
    "## first we will annotate images using roboflow then convert json annotation to yolo format\n",
    "## Create a label for each image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "914c0cb6-f25f-4252-b245-b573cc99231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_data = {\n",
    "#     \"boxes\": [\n",
    "#         {\n",
    "#             \"id\": \"1\",\n",
    "#             \"label\": \"nom et prenom de adherent\",\n",
    "#             \"x\": \"995.57\",\n",
    "#             \"y\": \"304.40\",\n",
    "#             \"width\": \"868.70\",\n",
    "#             \"height\": \"90.84\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"2\",\n",
    "#             \"label\": \"numero cin ou passeport\",\n",
    "#             \"x\": \"840.38\",\n",
    "#             \"y\": \"372.03\",\n",
    "#             \"width\": \"649.09\",\n",
    "#             \"height\": \"83.90\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"3\",\n",
    "#             \"label\": \"addresse de ladherent\",\n",
    "#             \"x\": \"967.43\",\n",
    "#             \"y\": \"442.23\",\n",
    "#             \"width\": \"1048.40\",\n",
    "#             \"height\": \"91.19\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"4\",\n",
    "#             \"label\": \"matricule cnam\",\n",
    "#             \"x\": \"767.91\",\n",
    "#             \"y\": \"510.50\",\n",
    "#             \"width\": \"691.69\",\n",
    "#             \"height\": \"78.14\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"5\",\n",
    "#             \"label\": \"matricule de adherent\",\n",
    "#             \"x\": \"998.70\",\n",
    "#             \"y\": \"583.99\",\n",
    "#             \"width\": \"1043.98\",\n",
    "#             \"height\": \"81.94\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"6\",\n",
    "#             \"label\": \"nom et prenom du malade\",\n",
    "#             \"x\": \"974.58\",\n",
    "#             \"y\": \"1188.24\",\n",
    "#             \"width\": \"905.32\",\n",
    "#             \"height\": \"107.15\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"7\",\n",
    "#             \"label\": \"date de naissance\",\n",
    "#             \"x\": \"956.30\",\n",
    "#             \"y\": \"1268.14\",\n",
    "#             \"width\": \"1113.70\",\n",
    "#             \"height\": \"101.14\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"8\",\n",
    "#             \"label\": \"date\",\n",
    "#             \"x\": \"269.77\",\n",
    "#             \"y\": \"1787.89\",\n",
    "#             \"width\": \"418.95\",\n",
    "#             \"height\": \"714.79\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"9\",\n",
    "#             \"label\": \"designation\",\n",
    "#             \"x\": \"509.45\",\n",
    "#             \"y\": \"1786.38\",\n",
    "#             \"width\": \"337.73\",\n",
    "#             \"height\": \"711.78\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"A\",\n",
    "#             \"label\": \"honoraire\",\n",
    "#             \"x\": \"827.48\",\n",
    "#             \"y\": \"1796.56\",\n",
    "#             \"width\": \"364.90\",\n",
    "#             \"height\": \"739.67\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"B\",\n",
    "#             \"label\": \"id\",\n",
    "#             \"x\": \"965.35\",\n",
    "#             \"y\": \"119.05\",\n",
    "#             \"width\": \"434.39\",\n",
    "#             \"height\": \"77.00\",\n",
    "#             \"confidence\": None\n",
    "#         }\n",
    "#     ],\n",
    "#     \"height\": 2476,\n",
    "#     \"key\": \"13237--9402439--20231122_page_00.jpg\",\n",
    "#     \"width\": 1747\n",
    "# }\n",
    "\n",
    "# json_data = {\n",
    "#     \"boxes\": [\n",
    "#         {\n",
    "#             \"id\": \"1\",\n",
    "#             \"label\": \"nom et prenom de adherent\",\n",
    "#             \"x\": \"994.58\",\n",
    "#             \"y\": \"280.82\",\n",
    "#             \"width\": \"869.65\",\n",
    "#             \"height\": \"103.09\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"3\",\n",
    "#             \"label\": \"addresse de ladherent\",\n",
    "#             \"x\": \"968.29\",\n",
    "#             \"y\": \"424.44\",\n",
    "#             \"width\": \"1042.39\",\n",
    "#             \"height\": \"93.48\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"2\",\n",
    "#             \"label\": \"numero cin ou passeport\",\n",
    "#             \"x\": \"834.37\",\n",
    "#             \"y\": \"353.79\",\n",
    "#             \"width\": \"649.36\",\n",
    "#             \"height\": \"85.95\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"4\",\n",
    "#             \"label\": \"matricule cnam\",\n",
    "#             \"x\": \"762.47\",\n",
    "#             \"y\": \"487.58\",\n",
    "#             \"width\": \"684.40\",\n",
    "#             \"height\": \"87.42\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"5\",\n",
    "#             \"label\": \"matricule de adherent\",\n",
    "#             \"x\": \"976.32\",\n",
    "#             \"y\": \"561.98\",\n",
    "#             \"width\": \"1040.58\",\n",
    "#             \"height\": \"92.86\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"6\",\n",
    "#             \"label\": \"nom et prenom du malade\",\n",
    "#             \"x\": \"972.04\",\n",
    "#             \"y\": \"1175.40\",\n",
    "#             \"width\": \"903.24\",\n",
    "#             \"height\": \"125.34\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"7\",\n",
    "#             \"label\": \"date de naissance\",\n",
    "#             \"x\": \"947.17\",\n",
    "#             \"y\": \"1249.44\",\n",
    "#             \"width\": \"1107.46\",\n",
    "#             \"height\": \"94.60\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"8\",\n",
    "#             \"label\": \"date\",\n",
    "#             \"x\": \"277.87\",\n",
    "#             \"y\": \"1806.03\",\n",
    "#             \"width\": \"409.10\",\n",
    "#             \"height\": \"796.46\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"9\",\n",
    "#             \"label\": \"designation\",\n",
    "#             \"x\": \"508.23\",\n",
    "#             \"y\": \"1764.35\",\n",
    "#             \"width\": \"360.59\",\n",
    "#             \"height\": \"716.67\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"A\",\n",
    "#             \"label\": \"honoraire\",\n",
    "#             \"x\": \"820.98\",\n",
    "#             \"y\": \"1797.98\",\n",
    "#             \"width\": \"348.12\",\n",
    "#             \"height\": \"783.93\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"B\",\n",
    "#             \"label\": \"id\",\n",
    "#             \"x\": \"958.95\",\n",
    "#             \"y\": \"85.32\",\n",
    "#             \"width\": \"428.72\",\n",
    "#             \"height\": \"86.46\",\n",
    "#             \"confidence\": None\n",
    "#         }\n",
    "#     ],\n",
    "#     \"height\": 2460,\n",
    "#     \"key\": \"0710--8574221--20230705_page_0.jpg\",\n",
    "#     \"width\": 3535\n",
    "# }\n",
    "# Star 1 pages\n",
    "# json_data = {\n",
    "#     \"boxes\": [\n",
    "#         {\n",
    "#             \"id\": \"1\",\n",
    "#             \"label\": \"addresse de ladherent\",\n",
    "#             \"x\": \"770.66\",\n",
    "#             \"y\": \"527.21\",\n",
    "#             \"width\": \"369.83\",\n",
    "#             \"height\": \"49.76\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"2\",\n",
    "#             \"label\": \"nom et prenom de adherent\",\n",
    "#             \"x\": \"757.01\",\n",
    "#             \"y\": \"480.59\",\n",
    "#             \"width\": \"463.60\",\n",
    "#             \"height\": \"34.32\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"3\",\n",
    "#             \"label\": \"matricule de adherent\",\n",
    "#             \"x\": \"773.06\",\n",
    "#             \"y\": \"350.28\",\n",
    "#             \"width\": \"305.61\",\n",
    "#             \"height\": \"53.81\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"4\",\n",
    "#             \"label\": \"matricule cnam\",\n",
    "#             \"x\": \"778.72\",\n",
    "#             \"y\": \"309.61\",\n",
    "#             \"width\": \"316.92\",\n",
    "#             \"height\": \"44.60\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"5\",\n",
    "#             \"label\": \"id\",\n",
    "#             \"x\": \"595.31\",\n",
    "#             \"y\": \"162.20\",\n",
    "#             \"width\": \"126.83\",\n",
    "#             \"height\": \"31.29\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"6\",\n",
    "#             \"label\": \"date\",\n",
    "#             \"x\": \"938.92\",\n",
    "#             \"y\": \"657.72\",\n",
    "#             \"width\": \"112.67\",\n",
    "#             \"height\": \"38.04\",\n",
    "#             \"confidence\": None\n",
    "#         }\n",
    "#     ],\n",
    "#     \"height\": 770,\n",
    "#     \"key\": \"form_10227_front.jpg\",\n",
    "#     \"width\": 1002\n",
    "# }\n",
    "# Bh 1 pages\n",
    "# json_data = {\n",
    "#     \"boxes\": [\n",
    "#         {\n",
    "#             \"id\": \"1\",\n",
    "#             \"label\": \"matricule cnam\",\n",
    "#             \"x\": \"276.51\",\n",
    "#             \"y\": \"300.25\",\n",
    "#             \"width\": \"326.48\",\n",
    "#             \"height\": \"42.48\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"2\",\n",
    "#             \"label\": \"matricule de adherent\",\n",
    "#             \"x\": \"274.70\",\n",
    "#             \"y\": \"341.28\",\n",
    "#             \"width\": \"307.89\",\n",
    "#             \"height\": \"46.42\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"3\",\n",
    "#             \"label\": \"id\",\n",
    "#             \"x\": \"92.31\",\n",
    "#             \"y\": \"163.39\",\n",
    "#             \"width\": \"129.06\",\n",
    "#             \"height\": \"45.11\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"4\",\n",
    "#             \"label\": \"nom et prenom de adherent\",\n",
    "#             \"x\": \"268.91\",\n",
    "#             \"y\": \"477.37\",\n",
    "#             \"width\": \"415.36\",\n",
    "#             \"height\": \"38.11\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"5\",\n",
    "#             \"label\": \"addresse de ladherent\",\n",
    "#             \"x\": \"272.84\",\n",
    "#             \"y\": \"510.60\",\n",
    "#             \"width\": \"369.36\",\n",
    "#             \"height\": \"49.73\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"6\",\n",
    "#             \"label\": \"date\",\n",
    "#             \"x\": \"432.50\",\n",
    "#             \"y\": \"652.28\",\n",
    "#             \"width\": \"133.03\",\n",
    "#             \"height\": \"32.34\",\n",
    "#             \"confidence\": None\n",
    "#         }\n",
    "#     ],\n",
    "#     \"height\": 770,\n",
    "#     \"key\": \"form_10271_front_right.jpg\",\n",
    "#     \"width\": 501\n",
    "# }\n",
    "# Bh 2 pages\n",
    "# json_data = {\n",
    "#     \"boxes\": [\n",
    "#         {\n",
    "#             \"id\": \"1\",\n",
    "#             \"label\": \"addresse de ladherent\",\n",
    "#             \"x\": \"770.66\",\n",
    "#             \"y\": \"527.21\",\n",
    "#             \"width\": \"369.83\",\n",
    "#             \"height\": \"49.76\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"2\",\n",
    "#             \"label\": \"nom et prenom de adherent\",\n",
    "#             \"x\": \"757.01\",\n",
    "#             \"y\": \"480.59\",\n",
    "#             \"width\": \"463.60\",\n",
    "#             \"height\": \"34.32\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"3\",\n",
    "#             \"label\": \"matricule de adherent\",\n",
    "#             \"x\": \"773.06\",\n",
    "#             \"y\": \"350.28\",\n",
    "#             \"width\": \"305.61\",\n",
    "#             \"height\": \"53.81\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"4\",\n",
    "#             \"label\": \"matricule cnam\",\n",
    "#             \"x\": \"778.72\",\n",
    "#             \"y\": \"309.61\",\n",
    "#             \"width\": \"316.92\",\n",
    "#             \"height\": \"44.60\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"5\",\n",
    "#             \"label\": \"id\",\n",
    "#             \"x\": \"595.31\",\n",
    "#             \"y\": \"162.20\",\n",
    "#             \"width\": \"126.83\",\n",
    "#             \"height\": \"31.29\",\n",
    "#             \"confidence\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"id\": \"6\",\n",
    "#             \"label\": \"date\",\n",
    "#             \"x\": \"938.92\",\n",
    "#             \"y\": \"657.72\",\n",
    "#             \"width\": \"112.67\",\n",
    "#             \"height\": \"38.04\",\n",
    "#             \"confidence\": None\n",
    "#         }\n",
    "#     ],\n",
    "#     \"height\": 770,\n",
    "#     \"key\": \"form_10227_front.jpg\",\n",
    "#     \"width\": 1002\n",
    "# }\n",
    "#cnam\n",
    "json_data = {\n",
    "    \"boxes\": [\n",
    "        {\n",
    "            \"id\": \"1\",\n",
    "            \"label\": \"id\",\n",
    "            \"x\": \"1614.94\",\n",
    "            \"y\": \"225.43\",\n",
    "            \"width\": \"193.75\",\n",
    "            \"height\": \"79.43\",\n",
    "            \"confidence\": None\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"2\",\n",
    "            \"label\": \"matricule de adherent\",\n",
    "            \"x\": \"1311.73\",\n",
    "            \"y\": \"386.44\",\n",
    "            \"width\": \"374.87\",\n",
    "            \"height\": \"73.51\",\n",
    "            \"confidence\": None\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"3\",\n",
    "            \"label\": \"nom et prenom de adherent\",\n",
    "            \"x\": \"1316.96\",\n",
    "            \"y\": \"518.78\",\n",
    "            \"width\": \"543.15\",\n",
    "            \"height\": \"43.19\",\n",
    "            \"confidence\": None\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"4\",\n",
    "            \"label\": \"nom et prenom de adherent\",\n",
    "            \"x\": \"1306.79\",\n",
    "            \"y\": \"558.47\",\n",
    "            \"width\": \"556.09\",\n",
    "            \"height\": \"37.81\",\n",
    "            \"confidence\": None\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"6\",\n",
    "            \"label\": \"nom et prenom du malade\",\n",
    "            \"x\": \"1316.11\",\n",
    "            \"y\": \"853.39\",\n",
    "            \"width\": \"530.05\",\n",
    "            \"height\": \"38.90\",\n",
    "            \"confidence\": None\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"7\",\n",
    "            \"label\": \"nom et prenom du malade\",\n",
    "            \"x\": \"1310.18\",\n",
    "            \"y\": \"886.75\",\n",
    "            \"width\": \"544.38\",\n",
    "            \"height\": \"37.69\",\n",
    "            \"confidence\": None\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"8\",\n",
    "            \"label\": \"date de naissance\",\n",
    "            \"x\": \"1331.99\",\n",
    "            \"y\": \"928.45\",\n",
    "            \"width\": \"410.77\",\n",
    "            \"height\": \"38.00\",\n",
    "            \"confidence\": None\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"5\",\n",
    "            \"label\": \"addresse de ladherent\",\n",
    "            \"x\": \"1309.71\",\n",
    "            \"y\": \"594.35\",\n",
    "            \"width\": \"526.82\",\n",
    "            \"height\": \"51.18\",\n",
    "            \"confidence\": None\n",
    "        }\n",
    "    ],\n",
    "    \"height\": 1241,\n",
    "    \"key\": \"cnam_front_00I0SF.jpg\",\n",
    "    \"width\": 1754\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f00bf23-f9cf-4f14-b131-5593dd5c2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_json_to_yolo(json_data, output_dir=\"labels\"):\n",
    "\n",
    "    class_mapping = {\n",
    "        \"nom et prenom de adherent\": 0,\n",
    "        \"matricule cnam\": 1,\n",
    "        \"matricule de adherent\": 2,\n",
    "        \"addresse de ladherent\": 3,\n",
    "        \"numero cin ou passeport\": 4,\n",
    "        \"nom et prenom du malade\": 5,\n",
    "        \"date de naissance\": 6,\n",
    "        \"date\": 7,\n",
    "        \"designation\": 8,\n",
    "        \"honoraire\": 9,\n",
    "        \"id\":10\n",
    "    }\n",
    "\n",
    "    # Extract image dimensions\n",
    "    image_width = json_data[\"width\"]\n",
    "    image_height = json_data[\"height\"]\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Determine output file path from the key\n",
    "    output_file = os.path.join(output_dir, os.path.splitext(json_data[\"key\"])[0] + \".txt\")\n",
    "    \n",
    "    # Write YOLO formatted annotations\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for box in json_data[\"boxes\"]:\n",
    "            try:\n",
    "                # Convert box coordinates from strings to float\n",
    "                center_x = float(box[\"x\"])\n",
    "                center_y = float(box[\"y\"])\n",
    "                width = float(box[\"width\"])\n",
    "                height = float(box[\"height\"])\n",
    "\n",
    "                # Normalize\n",
    "                center_x_norm = center_x / image_width\n",
    "                center_y_norm = center_y / image_height\n",
    "                width_norm = width / image_width\n",
    "                height_norm = height / image_height\n",
    "\n",
    "                # Get the class ID\n",
    "                label = box[\"label\"]\n",
    "                if label not in class_mapping:\n",
    "                    print(f\"Warning: Label '{label}' not found in class mapping. Skipping.\")\n",
    "                    continue\n",
    "                class_id = class_mapping[label]\n",
    "\n",
    "                # Write to file\n",
    "                f.write(f\"{class_id} {center_x_norm:.6f} {center_y_norm:.6f} {width_norm:.6f} {height_norm:.6f}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing box with ID {box.get('id')}: {e}\")\n",
    "\n",
    "    print(f\"Saved YOLO annotations to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2eb78b4-16f8-499b-aa43-dd8d6509401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_folder = \"data_to_annotate/cnam_temp\"\n",
    "# for filename in os.listdir(source_folder):\n",
    "#     if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "#         path = os.path.join(source_folder, filename)\n",
    "#         json_data[\"key\"]=filename\n",
    "#         convert_json_to_yolo(json_data)\n",
    "#         print(f'label created : {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02eb8d05-7828-429f-bcbc-dd86fefd36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "def annotate_image(image_path, label_path, output_dir=\"output_annotated\"):\n",
    "# Define the class names globally or pass them as a parameter if needed\n",
    "    class_names = [\n",
    "        \"nom et prenom de adherent\",\n",
    "        \"matricule cnam\",\n",
    "        \"matricule de adherent\",\n",
    "        \"addresse de ladherent\",\n",
    "        \"numero cin ou passeport\",\n",
    "        \"nom et prenom du malade\",\n",
    "        \"date de naissance\",\n",
    "        \"date\",\n",
    "        \"designation\",\n",
    "        \"honoraire\",\n",
    "        \"id\"\n",
    "    ]\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Could not load image at {image_path}\")\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Read the YOLO annotations\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Draw each bounding box on the image\n",
    "    for line in lines:\n",
    "        # Parse the YOLO annotation line\n",
    "        class_id, center_x, center_y, box_width, box_height = map(float, line.strip().split())\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        x_min = int((center_x - box_width / 2) * width)\n",
    "        y_min = int((center_y - box_height / 2) * height)\n",
    "        x_max = int((center_x + box_width / 2) * width)\n",
    "        y_max = int((center_y + box_height / 2) * height)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        color = (0, 255, 0)  # Green color in BGR\n",
    "        thickness = 2\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, thickness)\n",
    "\n",
    "        # Add the class label above the box\n",
    "        label = class_names[class_id]\n",
    "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Generate the output path\n",
    "    file_name = os.path.basename(image_path)\n",
    "    name, ext = os.path.splitext(file_name)\n",
    "    output_path = os.path.join(output_dir, f\"{name}_annotated{ext}\")\n",
    "\n",
    "    # Save the annotated image\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Saved annotated image to {output_path}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8fa21b8-0d90-409e-9cbf-66b9c7fed3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_folder = \"data_to_annotate/cnam_temp\"\n",
    "# for filename in os.listdir(source_folder):\n",
    "#     if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "#         path = os.path.join(source_folder, filename)\n",
    "#         image_path = source_folder+\"/\"+filename\n",
    "#         name_without_extension = os.path.splitext(filename)[0]\n",
    "#         label_path = f\"labels/{name_without_extension}.txt\"\n",
    "#         annotate_image(image_path, label_path)\n",
    "#         print(f'Bounding box created : {filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d26c0-dfa6-43df-ad41-743308b8aa16",
   "metadata": {},
   "source": [
    "## Creation of dataset structure\n",
    "##### data/\n",
    "##### ├── dataset/\n",
    "##### │   ├── images/\n",
    "##### │   │   ├── train/\n",
    "##### │   │   │   ├── image1.jpg\n",
    "##### │   │   │   └── ...\n",
    "##### │   │   ├── val/\n",
    "##### │   │   │   ├── image2.jpg\n",
    "##### │   │   │   └── ...\n",
    "##### │   │   └── test/\n",
    "##### │   │       ├── 0712--9550810--20230705_page_0.jpg\n",
    "##### │   │       └── ...\n",
    "##### │   ├── labels/\n",
    "##### │   │   ├── train/\n",
    "##### │   │   │   ├── image1.txt\n",
    "##### │   │   │   └── ...\n",
    "##### │   │   ├── val/\n",
    "##### │   │   │   ├── image2.txt\n",
    "##### │   │   │   └── ...\n",
    "##### │   │   └── test/\n",
    "##### │   │       ├── 0712--9550810--20230705_page_0.txt\n",
    "##### │   │       └── ...\n",
    "##### │   └── data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23fe38cc-e378-4fcd-bdd8-890b098074fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying training files...\n",
      "Copying validation files...\n",
      "Copying test files...\n",
      "Dataset split complete. Created dataset\\data.yaml\n",
      "Train: 3003 images\n",
      "Validation: 858 images\n",
      "Test: 430 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "image_dir = \"Medical_form\"\n",
    "label_dir = \"labels\"\n",
    "output_dir = \"dataset\"\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.2    # 20% for validation\n",
    "test_ratio = 0.1   # 10% for testing\n",
    "\n",
    "# Define class names (assuming a single class for handwritten regions)\n",
    "class_names = [\n",
    "    \"nom et prenom de adherent\",\n",
    "    \"matricule cnam\",\n",
    "    \"matricule de adherent\",\n",
    "    \"addresse de ladherent\",\n",
    "    \"numero cin ou passeport\",\n",
    "    \"nom et prenom du malade\",\n",
    "    \"date de naissance\",\n",
    "    \"date\",\n",
    "    \"designation\",\n",
    "    \"honoraire\",\n",
    "    \"id\"\n",
    "]\n",
    "\n",
    "# Create output directories\n",
    "image_train_dir = os.path.join(output_dir, \"images\", \"train\")\n",
    "image_val_dir = os.path.join(output_dir, \"images\", \"val\")\n",
    "image_test_dir = os.path.join(output_dir, \"images\", \"test\")\n",
    "label_train_dir = os.path.join(output_dir, \"labels\", \"train\")\n",
    "label_val_dir = os.path.join(output_dir, \"labels\", \"val\")\n",
    "label_test_dir = os.path.join(output_dir, \"labels\", \"test\")\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(image_train_dir, exist_ok=True)\n",
    "os.makedirs(image_val_dir, exist_ok=True)\n",
    "os.makedirs(image_test_dir, exist_ok=True)\n",
    "os.makedirs(label_train_dir, exist_ok=True)\n",
    "os.makedirs(label_val_dir, exist_ok=True)\n",
    "os.makedirs(label_test_dir, exist_ok=True)\n",
    "\n",
    "# Get list of all images\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "random.shuffle(image_files)  # Shuffle the list to randomize the split\n",
    "\n",
    "# Calculate split indices\n",
    "total_images = len(image_files)\n",
    "train_end = int(total_images * train_ratio)\n",
    "val_end = train_end + int(total_images * val_ratio)\n",
    "\n",
    "# Split the images\n",
    "train_files = image_files[:train_end]\n",
    "val_files = image_files[train_end:val_end]\n",
    "test_files = image_files[val_end:]\n",
    "\n",
    "# Function to copy files to the appropriate directory\n",
    "def copy_files(file_list, src_image_dir, src_label_dir, dst_image_dir, dst_label_dir):\n",
    "    for file_name in file_list:\n",
    "        # Copy image\n",
    "        src_image_path = os.path.join(src_image_dir, file_name)\n",
    "        dst_image_path = os.path.join(dst_image_dir, file_name)\n",
    "        shutil.copy2(src_image_path, dst_image_path)\n",
    "        \n",
    "        # Copy corresponding label file\n",
    "        label_file = os.path.splitext(file_name)[0] + \".txt\"\n",
    "        src_label_path = os.path.join(src_label_dir, label_file)\n",
    "        dst_label_path = os.path.join(dst_label_dir, label_file)\n",
    "        if os.path.exists(src_label_path):\n",
    "            shutil.copy2(src_label_path, dst_label_path)\n",
    "        else:\n",
    "            print(f\"Warning: Label file {src_label_path} not found for image {file_name}\")\n",
    "\n",
    "# Copy files to their respective directories\n",
    "print(\"Copying training files...\")\n",
    "copy_files(train_files, image_dir, label_dir, image_train_dir, label_train_dir)\n",
    "print(\"Copying validation files...\")\n",
    "copy_files(val_files, image_dir, label_dir, image_val_dir, label_val_dir)\n",
    "print(\"Copying test files...\")\n",
    "copy_files(test_files, image_dir, label_dir, image_test_dir, label_test_dir)\n",
    "\n",
    "# Create data.yaml file\n",
    "data_yaml = f\"\"\"\n",
    "train: {os.path.abspath(image_train_dir)}\n",
    "val: {os.path.abspath(image_val_dir)}\n",
    "test: {os.path.abspath(image_test_dir)}\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "# Save data.yaml\n",
    "data_yaml_path = os.path.join(output_dir, \"data.yaml\")\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(data_yaml)\n",
    "\n",
    "print(f\"Dataset split complete. Created {data_yaml_path}\")\n",
    "print(f\"Train: {len(train_files)} images\")\n",
    "print(f\"Validation: {len(val_files)} images\")\n",
    "print(f\"Test: {len(test_files)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3fc05b-0def-4d89-98aa-6debfde8adc1",
   "metadata": {},
   "source": [
    "## installing libraries for YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c2dabc5-b9f7-47ac-a61d-98b23cd0a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics==8.2.48\n",
      "  Downloading ultralytics-8.2.48-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (1.26.4)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics==8.2.48)\n",
      "  Using cached matplotlib-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (4.10.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (0.18.1a0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (5.9.0)\n",
      "Collecting py-cpuinfo (from ultralytics==8.2.48)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from ultralytics==8.2.48) (2.2.3)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics==8.2.48)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics==8.2.48)\n",
      "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics==8.2.48)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3.0->ultralytics==8.2.48)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics==8.2.48)\n",
      "  Using cached fonttools-4.57.0-cp310-cp310-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3.0->ultralytics==8.2.48)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.2.48) (24.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics==8.2.48)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.2.48) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.2.48) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.2.48) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.2.48) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.2.48) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.2.48) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.2.48) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.2.48) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.2.48) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.2.48) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.2.48) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.2.48) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.2.48) (2024.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.2.48) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.2.48) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics==8.2.48) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\medical_form\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics==8.2.48) (1.3.0)\n",
      "Downloading ultralytics-8.2.48-py3-none-any.whl (793 kB)\n",
      "   ---------------------------------------- 0.0/793.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 793.7/793.7 kB 4.9 MB/s eta 0:00:00\n",
      "Using cached matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.57.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: py-cpuinfo, pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, ultralytics-thop, seaborn, ultralytics\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 py-cpuinfo-9.0.0 pyparsing-3.2.3 seaborn-0.13.2 ultralytics-8.2.48 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics==8.2.48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b571ce-ca3c-4dc1-afdf-743bb4b984bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo --version\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7fad08-fd0e-40db-b4f9-dae6a8744bc1",
   "metadata": {},
   "source": [
    "## fine tunning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25f4e51-6374-458e-b15c-77c94f3d956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.111 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.107  Python-3.11.11 torch-2.5.1 CUDA:1 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=dataset/data.yaml, epochs=30, time=None, patience=5, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=1, workers=0, project=None, name=medical_form_yolo_star_bh_cnam_30_epoch8, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\medical_form_yolo_star_bh_cnam_30_epoch8\n",
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2120305  ultralytics.nn.modules.head.Detect           [11, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,139,857 parameters, 11,139,841 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\OneDrive - ESPRIT\\Bureau\\4DS\\Semester2\\Project\\ProjectDS\\modelling\\dataset\\labels\\train.cache... 3003 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3003/3003 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\OneDrive - ESPRIT\\Bureau\\4DS\\Semester2\\Project\\ProjectDS\\modelling\\dataset\\labels\\val.cache... 858 images, 0 backgrounds, 0 corrupt: 100%|██████████| 858/858 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\medical_form_yolo_star_bh_cnam_30_epoch8\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\medical_form_yolo_star_bh_cnam_30_epoch8\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      1.67G      1.813      2.026      1.618         83        640: 100%|██████████| 188/188 [02:57<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:38<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.821      0.833      0.887      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      2.75G      1.076     0.8392      1.161         90        640: 100%|██████████| 188/188 [02:46<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.884      0.933      0.961       0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      2.75G     0.9177     0.6833      1.066         86        640: 100%|██████████| 188/188 [02:48<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.952       0.97      0.978      0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      2.75G     0.8232     0.6016      1.012         91        640: 100%|██████████| 188/188 [02:47<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:34<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.978      0.968      0.984      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      2.75G     0.7519     0.5449     0.9792         90        640: 100%|██████████| 188/188 [02:45<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:33<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.974      0.978      0.982      0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      2.75G     0.7032     0.5042     0.9501         82        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:34<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.983      0.982      0.986      0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      2.75G     0.6558     0.4669     0.9337         84        640: 100%|██████████| 188/188 [02:46<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.976       0.98      0.984       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      2.75G     0.6416     0.4561     0.9251         86        640: 100%|██████████| 188/188 [02:48<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797       0.98      0.981      0.983      0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      2.75G     0.6323     0.4481     0.9174         85        640: 100%|██████████| 188/188 [02:50<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.982      0.982      0.983       0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      2.75G     0.6005     0.4287     0.9071         84        640: 100%|██████████| 188/188 [02:47<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:34<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.975      0.979      0.986      0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      2.75G     0.5899     0.4148     0.9008        101        640: 100%|██████████| 188/188 [02:47<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.987      0.986      0.988       0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      2.75G     0.5563     0.3948     0.8893         70        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.989      0.986      0.986      0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      2.75G     0.5466     0.3881     0.8871         85        640: 100%|██████████| 188/188 [02:48<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.987      0.987       0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      2.75G     0.5342     0.3753     0.8816         81        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:34<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.982      0.986      0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      2.75G     0.5227     0.3678     0.8784         85        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.987      0.987      0.859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      2.75G     0.5111     0.3596      0.875         87        640: 100%|██████████| 188/188 [02:48<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.986      0.987      0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      2.75G     0.4993     0.3497     0.8683         98        640: 100%|██████████| 188/188 [02:51<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:36<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.983      0.982      0.984      0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      2.75G     0.4973     0.3477     0.8672         96        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:36<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.984      0.986       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      2.75G     0.4793     0.3377     0.8618         85        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.983      0.987      0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      2.75G     0.4636     0.3287     0.8588         89        640: 100%|██████████| 188/188 [02:48<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.985      0.982      0.987      0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      2.75G     0.4542     0.3235     0.8571         96        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.981      0.977      0.984      0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      2.75G      0.447     0.3139     0.8557        100        640: 100%|██████████| 188/188 [02:50<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.983      0.987      0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      2.75G     0.4413     0.3127     0.8519         85        640: 100%|██████████| 188/188 [02:50<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:36<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.983      0.987      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      2.75G     0.4293     0.3039     0.8511         92        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.986      0.981      0.986      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      2.75G      0.421     0.2994      0.848         96        640: 100%|██████████| 188/188 [02:49<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.984       0.98      0.986      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      2.75G     0.4103      0.292     0.8456         99        640: 100%|██████████| 188/188 [02:50<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.987      0.981      0.986      0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      2.75G     0.4069     0.2892     0.8466         79        640: 100%|██████████| 188/188 [02:50<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.983      0.987      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      2.75G     0.4046     0.2874     0.8456         87        640: 100%|██████████| 188/188 [02:50<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.987      0.983      0.988      0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      2.75G      0.398     0.2846     0.8407         78        640: 100%|██████████| 188/188 [02:50<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:36<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.987      0.982      0.987      0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      2.75G     0.3988     0.2841     0.8426         91        640: 100%|██████████| 188/188 [02:51<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:35<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.987      0.982      0.987      0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 1.713 hours.\n",
      "Optimizer stripped from runs\\detect\\medical_form_yolo_star_bh_cnam_30_epoch8\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\medical_form_yolo_star_bh_cnam_30_epoch8\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\medical_form_yolo_star_bh_cnam_30_epoch8\\weights\\best.pt...\n",
      "Ultralytics 8.3.107  Python-3.11.11 torch-2.5.1 CUDA:1 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "Model summary (fused): 72 layers, 11,129,841 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:37<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        858       6797      0.988      0.983      0.987      0.899\n",
      "nom et prenom de adherent        858       1045      0.992      0.994      0.994      0.964\n",
      "        matricule cnam        671        671       0.99      0.987      0.989      0.911\n",
      " matricule de adherent        858        858      0.992      0.993      0.994      0.949\n",
      " addresse de ladherent        858        858      0.994      0.992      0.994      0.952\n",
      "numero cin ou passeport        255        255       0.98      0.976      0.965      0.643\n",
      "nom et prenom du malade        442        629      0.991       0.99      0.993      0.933\n",
      "     date de naissance        442        442      0.988      0.986      0.987      0.889\n",
      "                  date        671        671      0.997      0.996      0.995      0.944\n",
      "           designation        255        255      0.984      0.982      0.976      0.883\n",
      "             honoraire        255        255          1      0.998      0.995      0.887\n",
      "                    id        858        858      0.955      0.915      0.978      0.931\n",
      "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\medical_form_yolo_star_bh_cnam_30_epoch8\u001b[0m\n",
      "✅ Training complete. Check 'runs/detect/medical_form_yolo_star_bh_cnam_30_epoch/weights/' for saved model.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# Train\n",
    "model.train(\n",
    "    data=\"dataset/data.yaml\",  # Path to your dataset\n",
    "    epochs=30,                 # Number of epochs\n",
    "    imgsz=640,                 # Image size\n",
    "    batch=16,                   # Reduced batch size to lower memory usage\n",
    "    device=1,                  # Use GPU 0 (your Tesla T4)\n",
    "    workers=0,                 # Reduce number of DataLoader workers\n",
    "    patience=5,                # Early stopping patience\n",
    "    optimizer=\"AdamW\",         # Optimizer for fine-tuning\n",
    "    lr0=0.001,                 # Initial learning rate\n",
    "    cos_lr=True,               # Cosine learning rate scheduling\n",
    "    weight_decay=0.0005,       # Weight decay for regularization\n",
    "\n",
    "    # Data augmentation\n",
    "    hsv_h=0.015,               # Hue augmentation\n",
    "    hsv_s=0.7,                 # Saturation augmentation\n",
    "    hsv_v=0.4,                 # Brightness augmentation\n",
    "    degrees=0.0,               # Random rotation\n",
    "    translate=0.1,             # Random translation\n",
    "    scale=0.5,                 # Random scaling\n",
    "    shear=0.0,                 # Random shearing\n",
    "    mosaic=0.0,                # Mosaic augmentation\n",
    "\n",
    "    # Model-specific\n",
    "    freeze=10,                 # Freeze first 10 layers (backbone)\n",
    "    pretrained=True,           # Use pretrained weights\n",
    "\n",
    "    # Logging\n",
    "    name=\"medical_form_yolo_star_bh_cnam_30_epoch\",  # Name of the training run\n",
    "    save_period=-1             # Save only best and last weights\n",
    ")\n",
    "\n",
    "print(\"✅ Training complete. Check 'runs/detect/medical_form_yolo_star_bh_cnam_30_epoch/weights/' for saved model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a8ec764-b5c5-4c35-a3fc-4d32fc56b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 nom et prenom de adherent, 1 addresse de ladherent, 1 nom et prenom du malade, 1 date de naissance, 1 date, 2 honoraires, 140.8ms\n",
      "Speed: 2.9ms preprocess, 140.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Saved cropped region to predictions\\date_1.jpg\n",
      "Saved cropped region to predictions\\date_de_naissance_2.jpg\n",
      "Saved cropped region to predictions\\honoraire_3.jpg\n",
      "Saved cropped region to predictions\\nom_et_prenom_de_adherent_4.jpg\n",
      "Saved cropped region to predictions\\addresse_de_ladherent_5.jpg\n",
      "Saved cropped region to predictions\\honoraire_6.jpg\n",
      "Saved cropped region to predictions\\nom_et_prenom_du_malade_7.jpg\n",
      "Saved annotated image to predictions\\annotated_0756--5637850--20230705_page_0_1.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "model_path = \"runs/detect/medical_form_yolo_best2/weights/best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Define class names (must match the order in data.yaml)\n",
    "# Define class names (assuming a single class for handwritten regions)\n",
    "class_names = [\n",
    "    \"nom et prenom de adherent\",\n",
    "    \"matricule cnam\",\n",
    "    \"matricule de adherent\",\n",
    "    \"addresse de ladherent\",\n",
    "    \"numero cin ou passeport\",\n",
    "    \"nom et prenom du malade\",\n",
    "    \"date de naissance\",\n",
    "    \"date\",\n",
    "    \"designation\",\n",
    "    \"honoraire\",\n",
    "    \"id\",\n",
    "]\n",
    "\n",
    "# Create output folder for annotated images and cropped regions\n",
    "output_folder = \"predictions\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Path to the new image for prediction\n",
    "image_path = \"dataset/images/val/0756--5637850--20230705_page_0_1.jpg\"  # Replace with the path to your new image\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"Could not load image at {image_path}\")\n",
    "\n",
    "# Run inference\n",
    "results = model(image, imgsz=640, conf=0.5, device=None)  # Use GPU (device=0); set to None for CPU\n",
    "\n",
    "# Process the detected bounding boxes\n",
    "crop_counter = 1\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy  # Get bounding boxes in [x_min, y_min, x_max, y_max] format\n",
    "    confidences = result.boxes.conf  # Get confidence scores\n",
    "    class_ids = result.boxes.cls  # Get class IDs\n",
    "\n",
    "    for box, conf, cls_id in zip(boxes, confidences, class_ids):\n",
    "        # Extract bounding box coordinates\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        class_id = int(cls_id)\n",
    "        label = class_names[class_id]\n",
    "        confidence = float(conf)\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        color = (0, 255, 0)  # Green color in BGR\n",
    "        thickness = 2\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "        cv2.putText(image, f\"{label} ({confidence:.2f})\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "\n",
    "        # Apply 20px vertical padding for cropping\n",
    "        height, width = image.shape[:2]\n",
    "        padding = 20\n",
    "        x1 = max(0, x1)\n",
    "        x2 = min(width, x2)\n",
    "        y1 = max(0, y1 - padding)\n",
    "        y2 = min(height, y2 + padding)\n",
    "\n",
    "        # Crop the detected region\n",
    "        if x2 > x1 and y2 > y1:\n",
    "            cropped_image = image[y1:y2, x1:x2]\n",
    "            \n",
    "            # Save the cropped image\n",
    "            output_filename = f\"{label.replace(' ', '_')}_{crop_counter}.jpg\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            cv2.imwrite(output_path, cropped_image)\n",
    "            print(f\"Saved cropped region to {output_path}\")\n",
    "            crop_counter += 1\n",
    "\n",
    "# Save the annotated image\n",
    "image_filename = os.path.basename(image_path)\n",
    "annotated_image_path = os.path.join(output_folder, f\"annotated_{image_filename}\")\n",
    "cv2.imwrite(annotated_image_path, image)\n",
    "print(f\"Saved annotated image to {annotated_image_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e57dc7a-636d-40a0-b49f-3d8a08cc138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Count: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673b1d4-ac0f-4e21-b7bf-3a56a27b3a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb61a5-ece7-4e80-83a7-135ba9af7666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
